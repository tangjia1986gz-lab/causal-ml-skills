[
  {
    "paper_id": "f75b70c9d7078724b592ec3e21de705e7b6ff73f",
    "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
    "authors": [
      "V. Chernozhukov",
      "D. Chetverikov",
      "Mert Demirer",
      "E. Duflo",
      "Christian Hansen",
      "W. Newey",
      "J. Robins"
    ],
    "year": 2017,
    "venue": "",
    "citations": 3029,
    "abstract": null,
    "pdf_url": "https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf",
    "external_ids": {
      "MAG": "2622003161",
      "DOI": "10.1111/ectj.12097",
      "CorpusId": 21698746
    }
  },
  {
    "paper_id": "fe96483ba3f34ca4565e81a5cb130f66c02cf681",
    "title": "Inference on Treatment Effects after Selection Amongst High-Dimensional Controls",
    "authors": [
      "A. Belloni",
      "V. Chernozhukov",
      "Christian Hansen"
    ],
    "year": 2011,
    "venue": "",
    "citations": 1498,
    "abstract": "In this supplementary appendix we provide additional results, omitted proofs and extensive simulations that complement the analysis of the main text (arXiv:1201.0224).",
    "pdf_url": "https://arxiv.org/pdf/1201.0224",
    "external_ids": {
      "MAG": "2949399223",
      "ArXiv": "1305.6099",
      "DOI": "10.2139/ssrn.2051129",
      "CorpusId": 1095109
    }
  },
  {
    "paper_id": "920120cc842feea3296e4df1019364677c42429a",
    "title": "High-Dimensional Methods and Inference on Structural and Treatment Effects",
    "authors": [
      "A. Belloni",
      "V. Chernozhukov",
      "Christian Hansen"
    ],
    "year": 2013,
    "venue": "",
    "citations": 678,
    "abstract": null,
    "pdf_url": "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.28.2.29",
    "external_ids": {
      "MAG": "2105171386",
      "DOI": "10.1257/JEP.28.2.29",
      "CorpusId": 5782150
    }
  },
  {
    "paper_id": "72a1c4a898d54bc33e0d115fc850fd3b6415e3d2",
    "title": "Double/Debiased/Neyman Machine Learning of Treatment Effects",
    "authors": [
      "V. Chernozhukov",
      "D. Chetverikov",
      "Mert Demirer",
      "E. Duflo",
      "Christian Hansen",
      "W. Newey"
    ],
    "year": 2017,
    "venue": "",
    "citations": 389,
    "abstract": "Chernozhukov et al. (2016) provide a generic double/de-biased machine learning (ML) approach for obtaining valid inferential statements about focal parameters, using Neyman-orthogonal scores and cross-fitting, in settings where nuisance parameters are estimated using ML methods. In this note, we illustrate the application of this method in the context of estimating average treatment effects and average treatment effects on the treated using observational data.",
    "pdf_url": "https://arxiv.org/pdf/1701.08687",
    "external_ids": {
      "ArXiv": "1701.08687",
      "MAG": "2952265181",
      "DOI": "10.1257/AER.P20171038",
      "CorpusId": 21703700
    }
  },
  {
    "paper_id": "c2c52ccca6981b52c9a4dfa02da430da3d0fd121",
    "title": "Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments",
    "authors": [
      "V. Chernozhukov",
      "Mert Demirer",
      "E. Duflo",
      "Iván Fernández-Val"
    ],
    "year": 2017,
    "venue": "",
    "citations": 210,
    "abstract": "We propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. These key features include best linear predictors of the effects using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high dimensional settings, where the effects are proxied by machine learning methods. We post-process these proxies into the estimates of the key features. Our approach is generic, it can be used in conjunction with penalized methods, deep and shallow neural networks, canonical and new random forests, boosted trees, and ensemble methods. Our approach is agnostic and does not make unrealistic or hard-to-check assumptions; we don’t require conditions for consistency of the ML methods. Estimation and inference relies on repeated data splitting to avoid overfitting and achieve validity. For inference, we take medians of p-values and medians of confidence intervals, resulting from many different data splits, and then adjust their nominal level to guarantee uniform validity. This variational inference method is shown to be uniformly valid and quantifies the uncertainty coming from both parameter estimation and data splitting. The inference method could be of substantial independent interest in many machine learning applications. An empirical application to the impact of micro-credit on economic development illustrates the use of the approach in randomized experiments. An additional application to the impact of the gender discrimination on wages illustrates the potential use of the approach in observational studies, where machine learning methods can be used to condition flexibly on very high-dimensional controls.",
    "pdf_url": "http://www.nber.org/papers/w24678.pdf",
    "external_ids": {
      "MAG": "2775030505",
      "DOI": "10.1920/WP.CEM.2017.6117",
      "CorpusId": 52059449
    }
  }
]