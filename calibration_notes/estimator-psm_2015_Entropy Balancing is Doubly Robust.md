# æ ¡å‡†ç¬”è®°: Entropy Balancing is Doubly Robust

> **æŠ€èƒ½**: estimator-psm
> **è®ºæ–‡ ID**: 1b73a6de77d1e3c3c5bb588e761506f424d9c117
> **å¹´ä»½**: 2015
> **æœŸåˆŠ**: 
> **å¼•ç”¨æ•°**: 353

---

## æ‘˜è¦

Covariate balance is a conventional key diagnostic for methods estimating causal eï¬€ects from observational
studies. Recently, there is an emerging interest in directly incorporating covariate balance in the estimation.
We study a recently proposed entropy maximization method called Entropy Balancing (EB), which exactly
matches the covariate moments for the diï¬€erent experimental groups in its optimization problem. We show
EB is doubly robust with respect to linear outcome regression and logistic propensity score regression, and it
reaches the asymptotic semiparametric variance bound when both regressions are correctly speciï¬ed. This is
surprising to us because there is no attempt to model the outcome or the treatment assignment in the original
proposal of EB. Our theoretical results and simulations suggest that EB is a very appealing alternative to the
conventional weighting estimators that estimate the propensity score by maximum likelihood.

---

## æ ¸å¿ƒå‡è®¾

- Assumption 1: (strong ignorability). (ğ‘Œ(0), ğ‘Œ(1))âŠ¥ğ‘‡|ğ‘‹.

- Assumption 2: (overlap). 0 < P(ğ‘‡= 1|ğ‘‹) < 1.
Intuitively, the ï¬rst assumption says that the observed covariates contain all the information that may cause
the selection bias, i. e. there is no unmeasured confounding variable, and the second assumption ensures that
the bias-correction information is available across the entire domain of ğ‘‹.
Since the covariates ğ‘‹contain all the information of confounding bias, it is important to understand the
relationship between ğ‘‡, ğ‘Œand ğ‘‹. Under

- Assumption 1: (strong ignorability), the joint distribution of (ğ‘‹, ğ‘Œ, ğ‘‡) is
determined by the marginal distribution of ğ‘‹and two conditional distributions given ğ‘‹. The ï¬rst conditional
distribution ğ‘’(ğ‘‹) = ğ‘ƒ(ğ‘‡= 1|ğ‘‹) is often called the propensity score and plays a central role in causal inference
[1]. The second conditional distribution is the density of ğ‘Œ(0) and ğ‘Œ(1) given ğ‘‹. Since we only consider the
mean causal eï¬€ect in this paper, it suï¬€ices to study the mean regression functions ğ‘”0(ğ‘‹) = ğ¸[ğ‘Œ(

- Assumption 1: (strong ignorability) and

- Assumption 2: (overlap) be given. Additionally, assume the
expectation of c(x) exists and Var(Y(0)) < âˆ. Then Entropy Balancing is doubly robust (Property 1) in the sense that
(1) If logit(ğ‘’(ğ‘¥)) or ğ‘”0(ğ‘¥) is linear in ğ‘uï¿½(ğ‘¥), ğ‘—= 1, â€¦ , ğ‘…, then Ì‚ğ›¾EB is statistically consistent.
(2) Moreover, if logit(ğ‘’(ğ‘¥)), ğ‘”0(ğ‘¥) and ğ‘”1(ğ‘¥) are all linear in ğ‘uï¿½(ğ‘¥), ğ‘—= 1, â€¦ , ğ‘…, then Ì‚ğ›¾EB reaches the semiparamet-
ric variance bound of ğ›¾derived in Hahn [34]â€‹ with unknown propensity score.
We give two proofs of the ï¬

- Assumption 2: (overlap) with high probability.

- Assumption 2: (overlap) is satisï¬ed and the expectation of ğ‘(ğ‘‹) exist, then P(ğ‘¤EBexists) â†’1 as
ğ‘›â†’âˆ. Furthermore, âˆ‘uï¿½
uï¿½=1 (ğ‘¤EB
uï¿½)2 â†’0 in probability as ğ‘›â†’âˆ.
Proof. Since the expectation of ğ‘(ğ‘‹) exist, the weak law of large number says
Ì„ğ‘(1)
pâ†’Ì„ğ‘âˆ—(1) = E[ğ‘(ğ‘‹)|ğ‘‡= 1].
Therefore

- Assumption 2: (overlap) implies Ì„ğ‘âˆ—(1) hence ğµuï¿½( Ì„ğ‘âˆ—(1)) is in the interior of the convex hull of
Î©(ğ‘‹) for suï¬€iciently small ğœ€. Let ğ‘…uï¿½, ğ‘–= 1, â€¦ , 3uï¿½, be the 3uï¿½boxes centered at
Ì„ğ‘âˆ—(1) + 3
2ğœ€ğ‘, where ğ‘âˆˆuï¿½is a vector
that each entry can be âˆ’1, 0, or 1. It is easy to check that the sets ğ‘…uï¿½are disjoint and the convex hull of {ğ‘¥uï¿½}3uï¿½
uï¿½=1
contains ğµuï¿½( Ì„ğ‘âˆ—(1)) if ğ‘¥uï¿½âˆˆğ‘…uï¿½, ğ‘–= 1, â€¦ , 3uï¿½. Since 0 < ğ‘ƒ(ğ‘‡= 0|ğ‘‹) < 1, ğœŒ= minuï¿½P(ğ‘‹âˆˆğ‘…uï¿½|ğ‘‡= 0) > 0. This implies
P(âˆƒğ‘‹uï¿½âˆˆğ‘…uï¿½andğ‘‡uï¿½= 0, âˆ€ğ‘–= 1, â€¦ , 3uï¿½) â‰¥1 âˆ’
3u


---

## æ–¹æ³•è®º/è¯†åˆ«ç­–ç•¥

Ì‚ğ‘’(ğ‘¥), the corresponding weights

---

## ä¼°è®¡æ–¹æ³•

[21, 22], which is widely popular in survey sampling but perhaps not suï¬€iciently recognized in causal inference
[23]. The balancing constraints in this optimization problem result in unbiasedness of the PATT estimator un-
der linear outcome regression model. The dual optimization problem of EB is ï¬tting a logistic propensity score
model with a loss function diï¬€erent from the negative binomial likelihood. The Fisher-consistency of this loss
function (also called proper scoring rule in statistical decision theory, see e. g. Gneiting and Raftery [24]) ensures
the other half of double robustness â€“ consistency under correctly speciï¬ed propensity score model. Since EB
essentially just uses a diï¬€erent loss function, other types of propensity score models, for example the general-
ized additive models [25] can also easily be ï¬tted. A forthcoming article by Zhao [26] oï¬€ers more discussion
and extension to other weighted average treatment eï¬€ects.
Figure 1: The role of covariate balance in doubly robust estimation. Dashed arrows: conventional procedure to achieve
double robustness. Solid arrows: double robustness of Entropy Balancing via covariate balance.
2
Setting
First, we ï¬x some notations for the causal inference problem considered in this paper. We follow the potential
outcome language of Neyman [27] and Rubin [28]. In this causal model, each unit ğ‘–is associated with a pair of
potential outcomes: the response ğ‘Œuï¿½(1) that is realized if ğ‘‡uï¿½= 1 (treated), and another response ğ‘Œuï¿½(0) realized if
ğ‘‡uï¿½= 0 (control). We assume the observational units are independent and identically distributed samples from
a population, for which we wish to infer the treatmentâ€™s eï¬€ect. The main obstacle is that only one potential
outcome is observed: ğ‘Œuï¿½= ğ‘‡uï¿½ğ‘Œuï¿½(1) âˆ’(1 âˆ’ğ‘‡uï¿½)ğ‘Œuï¿½(0), which is commonly known as the â€œfundamental problem of
causal inferenceâ€ [29].
In this paper we focus on estimating the Population Average Treatment eï¬€ect on the Treated (PATT):
ğ›¾= E[ğ‘Œ(1)|ğ‘‡= 1] âˆ’E[ğ‘Œ(0)|ğ‘‡= 1]
Î”= ğœ‡(1|1) âˆ’ğœ‡(0|1).
(1)
The counterfactual mean ğœ‡(0|1) = E[ğ‘Œ(0)|ğ‘‡= 1] also naturally occurs in survey sampling with missing data
[21, 22] by viewing ğ‘Œ(0) as the only outcome of interest (so ğ‘‡= 1 stands for non-response).
Along with the treatment exposure ğ‘‡uï¿½and outcome ğ‘Œuï¿½, each unit ğ‘–is usually associated with a set of covari-
ates denoted by ğ‘‹uï¿½measured prior to the treatment assignment. In a typical observational study, both treatment
assignment and outcome may be related to the covariates, which can cause serious confounding bias. The sem-
inal work by Rosenbaum and Rubin [1] suggest that it is possible to correct the confounding bias under the
following two assumptions:


DE GRUYTER
Zhao and Percival
Assumption 1 (strong ignorability). (ğ‘Œ(0), ğ‘Œ(1))âŠ¥ğ‘‡|ğ‘‹.
Assumption 2 (overlap). 0 < P(ğ‘‡= 1|ğ‘‹) < 1.
Intuitively, the ï¬rst assumption says that the observed covariates contain all the information that may cause
the selection bias, i. e. there is no unmeasured confounding variable, and the second a

---

## å…³é”®å…¬å¼

æœªæå–åˆ°å…¬å¼

---

## æ ¡å‡†æ£€æŸ¥æ¸…å•

- [ ] è¯†åˆ«å‡è®¾æ˜¯å¦å®Œæ•´è¦†ç›–
- [ ] ä¼°è®¡æ–¹æ³•æ˜¯å¦å‡†ç¡®æè¿°
- [ ] è¯Šæ–­æ£€éªŒæ˜¯å¦åŒ…å«
- [ ] ä»£ç å®ç°æ˜¯å¦ä¸€è‡´
- [ ] å‚è€ƒæ–‡çŒ®æ˜¯å¦å¼•ç”¨

---

## ä¸ç°æœ‰æ–‡æ¡£çš„å·®å¼‚

<!-- ç”± CalibrationAgent è‡ªåŠ¨å¡«å†™ -->

