#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Report Generator - æ ¡å‡†æŠ¥å‘Šç”Ÿæˆå™¨

ç”Ÿæˆ:
1. ç»¼åˆæ ¡å‡†æŠ¥å‘Š (CALIBRATION_REPORT_{date}.md)
2. æŠ€èƒ½è¦†ç›–çŸ©é˜µ (SKILL_COVERAGE_MATRIX.md)
3. å¼•ç”¨æ•°æ®åº“ (CITATION_DATABASE.json)
4. å·®è·æ±‡æ€»æŠ¥å‘Š
5. è¿›åº¦ä»ªè¡¨æ¿
"""

import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
SKILLS_DIR = PROJECT_ROOT / "skills"
CALIBRATION_DIR = PROJECT_ROOT / "calibration_v2"
REPORTS_DIR = CALIBRATION_DIR / "reports"

# ç¡®ä¿ç›®å½•å­˜åœ¨
REPORTS_DIR.mkdir(parents=True, exist_ok=True)


# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class SkillMetrics:
    """æŠ€èƒ½æŒ‡æ ‡"""
    skill_name: str
    category: str
    priority: int
    papers_count: int = 0
    gaps_count: int = 0
    coverage_score: float = 0.0
    formula_score: float = 0.0
    citation_score: float = 0.0
    overall_score: float = 0.0
    passed: bool = False
    components_present: List[str] = field(default_factory=list)
    critical_gaps: int = 0
    major_gaps: int = 0
    minor_gaps: int = 0


@dataclass
class ReportData:
    """æŠ¥å‘Šæ•°æ®"""
    generated_at: datetime
    total_skills: int = 0
    skills_passed: int = 0
    skills_failed: int = 0
    total_papers: int = 0
    total_gaps: int = 0
    avg_score: float = 0.0
    skill_metrics: Dict[str, SkillMetrics] = field(default_factory=dict)
    category_breakdown: Dict[str, Dict[str, int]] = field(default_factory=dict)
    priority_breakdown: Dict[int, Dict[str, int]] = field(default_factory=dict)


# ============================================================================
# æŠ¥å‘Šç”Ÿæˆå™¨
# ============================================================================

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, calibration_dir: Optional[Path] = None):
        self.calibration_dir = calibration_dir or CALIBRATION_DIR
        self.results_dir = self.calibration_dir / "results"
        self.data = ReportData(generated_at=datetime.now())

    def load_results(self) -> None:
        """åŠ è½½æ‰€æœ‰æ ¡å‡†ç»“æœ"""
        if not self.results_dir.exists():
            print(f"ç»“æœç›®å½•ä¸å­˜åœ¨: {self.results_dir}")
            return

        for skill_dir in self.results_dir.iterdir():
            if not skill_dir.is_dir():
                continue

            result_file = skill_dir / "calibration_result.json"
            if not result_file.exists():
                continue

            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    result = json.load(f)

                skill_name = result.get("skill_name", skill_dir.name)

                # åŠ è½½å·®è·æ•°æ®
                gaps_dir = skill_dir / "gaps"
                critical = 0
                major = 0
                minor = 0

                if gaps_dir.exists():
                    for gap_file in gaps_dir.glob("*_gaps.json"):
                        with open(gap_file, 'r', encoding='utf-8') as f:
                            gap_data = json.load(f)
                            for gap in gap_data.get("gaps", []):
                                severity = gap.get("severity", "minor")
                                if severity == "critical":
                                    critical += 1
                                elif severity == "major":
                                    major += 1
                                else:
                                    minor += 1

                # ä»é…ç½®è·å–ç±»åˆ«å’Œä¼˜å…ˆçº§
                from config.calibration_config import SKILL_CALIBRATION_CONFIG
                config = SKILL_CALIBRATION_CONFIG.get(skill_name)
                category = config.category.value if config else "unknown"
                priority = config.priority.value if config else 4

                metrics = SkillMetrics(
                    skill_name=skill_name,
                    category=category,
                    priority=priority,
                    papers_count=result.get("papers_found", 0),
                    gaps_count=result.get("gaps_identified", 0),
                    formula_score=result.get("formula_score", 0.0),
                    citation_score=result.get("citation_score", 0.0),
                    overall_score=result.get("overall_score", 0.0),
                    passed=result.get("passed", False),
                    critical_gaps=critical,
                    major_gaps=major,
                    minor_gaps=minor,
                )

                self.data.skill_metrics[skill_name] = metrics
                self.data.total_skills += 1
                self.data.total_papers += metrics.papers_count
                self.data.total_gaps += metrics.gaps_count

                if metrics.passed:
                    self.data.skills_passed += 1
                else:
                    self.data.skills_failed += 1

            except Exception as e:
                print(f"åŠ è½½ {skill_dir.name} å¤±è´¥: {e}")

        # è®¡ç®—å¹³å‡åˆ†
        if self.data.skill_metrics:
            scores = [m.overall_score for m in self.data.skill_metrics.values() if m.overall_score > 0]
            self.data.avg_score = sum(scores) / len(scores) if scores else 0.0

        # æŒ‰ç±»åˆ«/ä¼˜å…ˆçº§æ±‡æ€»
        self._calculate_breakdowns()

    def _calculate_breakdowns(self) -> None:
        """è®¡ç®—ç±»åˆ«å’Œä¼˜å…ˆçº§åˆ†å¸ƒ"""
        category_stats = defaultdict(lambda: {"total": 0, "passed": 0, "failed": 0})
        priority_stats = defaultdict(lambda: {"total": 0, "passed": 0, "failed": 0})

        for metrics in self.data.skill_metrics.values():
            # ç±»åˆ«
            category_stats[metrics.category]["total"] += 1
            if metrics.passed:
                category_stats[metrics.category]["passed"] += 1
            else:
                category_stats[metrics.category]["failed"] += 1

            # ä¼˜å…ˆçº§
            priority_stats[metrics.priority]["total"] += 1
            if metrics.passed:
                priority_stats[metrics.priority]["passed"] += 1
            else:
                priority_stats[metrics.priority]["failed"] += 1

        self.data.category_breakdown = dict(category_stats)
        self.data.priority_breakdown = dict(priority_stats)

    def generate_main_report(self) -> str:
        """ç”Ÿæˆä¸»æ ¡å‡†æŠ¥å‘Š"""
        report = f"""# ç³»ç»Ÿæ€§æ–¹æ³•æ ¡å‡†æŠ¥å‘Š

> **ç”Ÿæˆæ—¶é—´**: {self.data.generated_at.strftime('%Y-%m-%d %H:%M:%S')}
> **æ¡†æ¶ç‰ˆæœ¬**: v2.0

---

## 1. æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šæ±‡æ€»äº†å¯¹ causal-ml-skills æ‰€æœ‰æŠ€èƒ½çš„ç³»ç»Ÿæ ¡å‡†ç»“æœï¼Œç¡®ä¿æ¯ä¸ªæ–¹æ³•è®ºå£°æ˜éƒ½æœ‰é¡¶åˆŠ/é«˜å¼•æ–‡çŒ®ä¾æ®ã€‚

### 1.1 å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **æ€»æŠ€èƒ½æ•°** | {self.data.total_skills} |
| **é€šè¿‡æŠ€èƒ½** | {self.data.skills_passed} âœ… |
| **æœªé€šè¿‡æŠ€èƒ½** | {self.data.skills_failed} âŒ |
| **é€šè¿‡ç‡** | {self.data.skills_passed / max(self.data.total_skills, 1):.1%} |
| **å¹³å‡å¾—åˆ†** | {self.data.avg_score:.1%} |
| **å¤„ç†è®ºæ–‡æ•°** | {self.data.total_papers} |
| **è¯†åˆ«å·®è·æ•°** | {self.data.total_gaps} |

### 1.2 çŠ¶æ€åˆ†å¸ƒ

```
é€šè¿‡ [{'â–ˆ' * int(self.data.skills_passed / max(self.data.total_skills, 1) * 20)}{'â–‘' * (20 - int(self.data.skills_passed / max(self.data.total_skills, 1) * 20))}] {self.data.skills_passed}/{self.data.total_skills}
```

---

## 2. æŒ‰ç±»åˆ«åˆ†æ

| ç±»åˆ« | æ€»æ•° | é€šè¿‡ | æœªé€šè¿‡ | é€šè¿‡ç‡ |
|------|------|------|--------|--------|
"""
        for category, stats in sorted(self.data.category_breakdown.items()):
            total = stats["total"]
            passed = stats["passed"]
            rate = passed / max(total, 1)
            report += f"| {category} | {total} | {passed} | {stats['failed']} | {rate:.1%} |\n"

        report += """

---

## 3. æŒ‰ä¼˜å…ˆçº§åˆ†æ

| ä¼˜å…ˆçº§ | æ€»æ•° | é€šè¿‡ | æœªé€šè¿‡ | é€šè¿‡ç‡ |
|--------|------|------|--------|--------|
"""
        for priority in sorted(self.data.priority_breakdown.keys()):
            stats = self.data.priority_breakdown[priority]
            total = stats["total"]
            passed = stats["passed"]
            rate = passed / max(total, 1)
            priority_label = {1: "P1 (Critical)", 2: "P2 (High)", 3: "P3 (Medium)", 4: "P4 (Low)"}.get(priority, f"P{priority}")
            report += f"| {priority_label} | {total} | {passed} | {stats['failed']} | {rate:.1%} |\n"

        report += """

---

## 4. å„æŠ€èƒ½è¯¦æƒ…

"""
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_skills = sorted(
            self.data.skill_metrics.values(),
            key=lambda x: (x.priority, -x.overall_score)
        )

        for metrics in sorted_skills:
            status = "âœ…" if metrics.passed else "âŒ"
            score_bar = "â–ˆ" * int(metrics.overall_score * 10) + "â–‘" * (10 - int(metrics.overall_score * 10))

            report += f"""### {status} {metrics.skill_name}

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| ç±»åˆ« | {metrics.category} |
| ä¼˜å…ˆçº§ | P{metrics.priority} |
| è®ºæ–‡æ•° | {metrics.papers_count} |
| å·®è·æ•° | {metrics.gaps_count} (ğŸ”´{metrics.critical_gaps} ğŸŸ¡{metrics.major_gaps} ğŸŸ¢{metrics.minor_gaps}) |
| å…¬å¼ä¸€è‡´æ€§ | {metrics.formula_score:.1%} |
| å¼•ç”¨è¦†ç›– | {metrics.citation_score:.1%} |
| **ç»¼åˆå¾—åˆ†** | [{score_bar}] {metrics.overall_score:.1%} |

"""

        report += """
---

## 5. å·®è·çƒ­åŠ›å›¾

"""
        # ç”Ÿæˆç®€å•çš„å·®è·çƒ­åŠ›å›¾
        report += "| æŠ€èƒ½ | å…³é”® | é‡è¦ | æ¬¡è¦ |\n"
        report += "|------|:----:|:----:|:----:|\n"

        for metrics in sorted_skills[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ª
            critical = "ğŸ”´" * min(metrics.critical_gaps, 5) or "-"
            major = "ğŸŸ¡" * min(metrics.major_gaps, 5) or "-"
            minor = "ğŸŸ¢" * min(metrics.minor_gaps, 5) or "-"
            report += f"| {metrics.skill_name} | {critical} | {major} | {minor} |\n"

        report += """

---

## 6. æ”¹è¿›å»ºè®®

### 6.1 ç´§æ€¥å¤„ç† (å…³é”®å·®è· > 0)

"""
        urgent = [m for m in sorted_skills if m.critical_gaps > 0]
        if urgent:
            for m in urgent[:5]:
                report += f"- **{m.skill_name}**: {m.critical_gaps} ä¸ªå…³é”®å·®è·éœ€è¦ä¿®å¤\n"
        else:
            report += "æ— ç´§æ€¥äº‹é¡¹ âœ…\n"

        report += """

### 6.2 é‡ç‚¹å…³æ³¨ (å¾—åˆ† < 70%)

"""
        low_score = [m for m in sorted_skills if m.overall_score < 0.7]
        if low_score:
            for m in low_score[:5]:
                report += f"- **{m.skill_name}**: å¾—åˆ† {m.overall_score:.1%}ï¼Œéœ€è¦æ”¹è¿›\n"
        else:
            report += "æ— é‡ç‚¹å…³æ³¨äº‹é¡¹ âœ…\n"

        report += f"""

---

## 7. é™„å½•

### 7.1 æ•°æ®æ¥æº

- æ ¡å‡†ç»“æœç›®å½•: `{self.results_dir}`
- é…ç½®æ–‡ä»¶: `scripts/config/calibration_config.py`
- ç”Ÿæˆè„šæœ¬: `scripts/report_generator.py`

### 7.2 è´¨é‡é—¨æ§æ ‡å‡†

| é—¨æ§ | é˜ˆå€¼ | æƒé‡ |
|------|------|------|
| æ–‡çŒ®è¦†ç›–åº¦ | â‰¥80% | 30% |
| å†…å®¹å®Œæ•´æ€§ | 100% | 30% |
| å…¬å¼ä¸€è‡´æ€§ | â‰¥90% | 20% |
| å¼•ç”¨æœ‰æ•ˆæ€§ | 100% | 20% |

---

*æŠ¥å‘Šç”±å¤šæ™ºèƒ½ä½“æ ¡å‡†æ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ*
"""
        return report

    def generate_coverage_matrix(self) -> str:
        """ç”ŸæˆæŠ€èƒ½è¦†ç›–çŸ©é˜µ"""
        report = """# æŠ€èƒ½è¦†ç›–çŸ©é˜µ

> æ­¤çŸ©é˜µæ˜¾ç¤ºæ¯ä¸ªæŠ€èƒ½çš„ç»„ä»¶å®Œæ•´æ€§çŠ¶æ€

| æŠ€èƒ½ | è¯†åˆ«å‡è®¾ | ä¼°è®¡æ–¹æ³• | è¯Šæ–­æµ‹è¯• | æŠ¥å‘Šæ ‡å‡† | å¸¸è§é”™è¯¯ | å¾—åˆ† |
|------|:--------:|:--------:|:--------:|:--------:|:--------:|:----:|
"""
        # æ‰«ææŠ€èƒ½ç›®å½•æ£€æŸ¥ç»„ä»¶
        for category_dir in SKILLS_DIR.iterdir():
            if not category_dir.is_dir():
                continue

            for skill_dir in category_dir.iterdir():
                if not skill_dir.is_dir():
                    continue

                refs_dir = skill_dir / "references"

                has_id = "âœ…" if (refs_dir / "identification_assumptions.md").exists() else "âŒ"
                has_est = "âœ…" if (refs_dir / "estimation_methods.md").exists() else "âŒ"
                has_diag = "âœ…" if (refs_dir / "diagnostic_tests.md").exists() else "âŒ"
                has_rep = "âœ…" if (refs_dir / "reporting_standards.md").exists() else "âŒ"
                has_err = "âœ…" if (refs_dir / "common_errors.md").exists() else "âŒ"

                # è·å–å¾—åˆ†
                metrics = self.data.skill_metrics.get(skill_dir.name)
                score = f"{metrics.overall_score:.1%}" if metrics else "-"

                report += f"| {skill_dir.name} | {has_id} | {has_est} | {has_diag} | {has_rep} | {has_err} | {score} |\n"

        return report

    def generate_citation_database(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¼•ç”¨æ•°æ®åº“"""
        from config.calibration_config import SKILL_CALIBRATION_CONFIG

        database = {
            "generated_at": self.data.generated_at.isoformat(),
            "skills": {}
        }

        for skill_name, config in SKILL_CALIBRATION_CONFIG.items():
            database["skills"][skill_name] = {
                "category": config.category.value,
                "priority": config.priority.value,
                "core_citations": config.core_citations,
                "queries": {
                    comp: {
                        "queries": qc.queries,
                        "min_citations": qc.min_citations,
                    }
                    for comp, qc in config.queries.items()
                }
            }

        return database

    def generate_gap_summary(self) -> str:
        """ç”Ÿæˆå·®è·æ±‡æ€»æŠ¥å‘Š"""
        report = """# å·®è·æ±‡æ€»æŠ¥å‘Š

> æ±‡æ€»æ‰€æœ‰æŠ€èƒ½çš„å·®è·åˆ†æç»“æœ

## 1. å·®è·ç»Ÿè®¡

| ä¸¥é‡ç¨‹åº¦ | æ•°é‡ | ç™¾åˆ†æ¯” |
|----------|------|--------|
"""
        total_critical = sum(m.critical_gaps for m in self.data.skill_metrics.values())
        total_major = sum(m.major_gaps for m in self.data.skill_metrics.values())
        total_minor = sum(m.minor_gaps for m in self.data.skill_metrics.values())
        total = total_critical + total_major + total_minor

        if total > 0:
            report += f"| ğŸ”´ å…³é”® | {total_critical} | {total_critical/total:.1%} |\n"
            report += f"| ğŸŸ¡ é‡è¦ | {total_major} | {total_major/total:.1%} |\n"
            report += f"| ğŸŸ¢ æ¬¡è¦ | {total_minor} | {total_minor/total:.1%} |\n"
        else:
            report += "| æ— å·®è· | 0 | - |\n"

        report += f"""

## 2. æŒ‰æŠ€èƒ½åˆ†å¸ƒ

| æŠ€èƒ½ | å…³é”® | é‡è¦ | æ¬¡è¦ | æ€»è®¡ |
|------|------|------|------|------|
"""
        for metrics in sorted(self.data.skill_metrics.values(), key=lambda x: -(x.critical_gaps + x.major_gaps)):
            total = metrics.critical_gaps + metrics.major_gaps + metrics.minor_gaps
            report += f"| {metrics.skill_name} | {metrics.critical_gaps} | {metrics.major_gaps} | {metrics.minor_gaps} | {total} |\n"

        return report

    def generate_all_reports(self) -> None:
        """ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Š"""
        print("æ­£åœ¨åŠ è½½æ ¡å‡†ç»“æœ...")
        self.load_results()

        if not self.data.skill_metrics:
            print("è­¦å‘Š: æœªæ‰¾åˆ°æ ¡å‡†ç»“æœ")

        timestamp = datetime.now().strftime("%Y-%m-%d")

        # 1. ä¸»æŠ¥å‘Š
        print("ç”Ÿæˆä¸»æ ¡å‡†æŠ¥å‘Š...")
        main_report = self.generate_main_report()
        main_path = REPORTS_DIR / f"CALIBRATION_REPORT_{timestamp}.md"
        main_path.write_text(main_report, encoding='utf-8')
        print(f"  -> {main_path}")

        # 2. è¦†ç›–çŸ©é˜µ
        print("ç”Ÿæˆè¦†ç›–çŸ©é˜µ...")
        coverage = self.generate_coverage_matrix()
        coverage_path = REPORTS_DIR / "SKILL_COVERAGE_MATRIX.md"
        coverage_path.write_text(coverage, encoding='utf-8')
        print(f"  -> {coverage_path}")

        # 3. å¼•ç”¨æ•°æ®åº“
        print("ç”Ÿæˆå¼•ç”¨æ•°æ®åº“...")
        citations = self.generate_citation_database()
        citations_path = REPORTS_DIR / "CITATION_DATABASE.json"
        with open(citations_path, 'w', encoding='utf-8') as f:
            json.dump(citations, f, ensure_ascii=False, indent=2)
        print(f"  -> {citations_path}")

        # 4. å·®è·æ±‡æ€»
        print("ç”Ÿæˆå·®è·æ±‡æ€»...")
        gaps = self.generate_gap_summary()
        gaps_path = REPORTS_DIR / "GAP_SUMMARY.md"
        gaps_path.write_text(gaps, encoding='utf-8')
        print(f"  -> {gaps_path}")

        print(f"\næ‰€æœ‰æŠ¥å‘Šå·²ç”Ÿæˆåˆ°: {REPORTS_DIR}")


# ============================================================================
# CLI å…¥å£
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="æ ¡å‡†æŠ¥å‘Šç”Ÿæˆå™¨"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="ç”Ÿæˆæ‰€æœ‰æŠ¥å‘Š"
    )
    parser.add_argument(
        "--main",
        action="store_true",
        help="ç”Ÿæˆä¸»æŠ¥å‘Š"
    )
    parser.add_argument(
        "--coverage",
        action="store_true",
        help="ç”Ÿæˆè¦†ç›–çŸ©é˜µ"
    )
    parser.add_argument(
        "--citations",
        action="store_true",
        help="ç”Ÿæˆå¼•ç”¨æ•°æ®åº“"
    )
    parser.add_argument(
        "--gaps",
        action="store_true",
        help="ç”Ÿæˆå·®è·æ±‡æ€»"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="è¾“å‡ºç›®å½•"
    )

    args = parser.parse_args()

    generator = ReportGenerator()

    if args.output:
        generator.calibration_dir = Path(args.output)

    if args.all or not any([args.main, args.coverage, args.citations, args.gaps]):
        generator.generate_all_reports()
    else:
        generator.load_results()

        if args.main:
            report = generator.generate_main_report()
            print(report)

        if args.coverage:
            matrix = generator.generate_coverage_matrix()
            print(matrix)

        if args.citations:
            db = generator.generate_citation_database()
            print(json.dumps(db, ensure_ascii=False, indent=2))

        if args.gaps:
            summary = generator.generate_gap_summary()
            print(summary)


if __name__ == "__main__":
    main()
