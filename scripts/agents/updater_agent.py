#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
UpdaterAgent - æ–‡æ¡£æ›´æ–°æ™ºèƒ½ä½“

èŒè´£:
1. æ ¹æ®å·®è·åˆ†æç”Ÿæˆæ›´æ–°è¡¥ä¸
2. åº”ç”¨æ›´æ–°åˆ°æŠ€èƒ½æ–‡æ¡£
3. ç»´æŠ¤æ›´æ–°å†å²
4. ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
"""

import sys
import re
import asyncio
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import json
import difflib

# Windows ç¼–ç ä¿®å¤
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

from .base import (
    BaseAgent, GapInfo,
    PROJECT_ROOT, SKILLS_DIR, CALIBRATION_DIR
)
from .gap_analyzer import GapAnalysisOutput


@dataclass
class UpdatePatch:
    """æ›´æ–°è¡¥ä¸"""
    patch_id: str
    target_file: str
    operation: str  # add, modify, delete
    location: str  # section name or line range
    original_content: str
    new_content: str
    reason: str
    source_gaps: List[str]  # gap_ids
    priority: int  # 1=highest
    applied: bool = False


@dataclass
class UpdateInput:
    """æ›´æ–°è¾“å…¥"""
    skill_name: str
    gap_results: Dict[str, GapAnalysisOutput]
    auto_apply: bool = False
    backup: bool = True


@dataclass
class UpdateOutput:
    """æ›´æ–°è¾“å‡º"""
    skill_name: str
    patches_generated: int
    patches_applied: int
    files_updated: List[str]
    patches: List[UpdatePatch]
    backup_path: Optional[Path]
    report: str


class UpdaterAgent(BaseAgent[UpdateInput, UpdateOutput]):
    """
    æ–‡æ¡£æ›´æ–°æ™ºèƒ½ä½“

    åŠŸèƒ½:
    - åˆ†æå·®è·ç”Ÿæˆè¡¥ä¸
    - æ™ºèƒ½å®šä½æ’å…¥ä½ç½®
    - å¤‡ä»½å’Œæ¢å¤
    - ç”Ÿæˆ diff æŠ¥å‘Š
    """

    # ç»„ä»¶åˆ°æ–‡ä»¶çš„æ˜ å°„
    COMPONENT_FILE_MAP = {
        "identification_assumptions": "references/identification_assumptions.md",
        "estimation_methods": "references/estimation_methods.md",
        "diagnostic_tests": "references/diagnostic_tests.md",
        "reporting_standards": "references/reporting_standards.md",
        "common_errors": "references/common_errors.md",
    }

    # å„ç»„ä»¶çš„å†…å®¹æ¨¡æ¿
    CONTENT_TEMPLATES = {
        "identification_assumptions": {
            "assumption": """
### {title}

**å½¢å¼åŒ–å®šä¹‰**:
{definition}

**ç›´è§‚è§£é‡Š**:
{intuition}

**å¯æµ‹è¯•æ€§**: {testability}

**æ–‡çŒ®æ¥æº**: {source}

---
""",
        },
        "estimation_methods": {
            "method": """
### {title}

**ä¼°è®¡é‡å…¬å¼**:
$$
{formula}
$$

**ç®—æ³•æ­¥éª¤**:
{steps}

**æ ‡å‡†è¯¯è®¡ç®—**:
{standard_errors}

**é€‚ç”¨æ¡ä»¶**: {conditions}

**å‚è€ƒ**: {source}

---
""",
        },
        "diagnostic_tests": {
            "test": """
### {title}

**æ£€éªŒç»Ÿè®¡é‡**:
$$
{statistic}
$$

**åŸå‡è®¾**: {null_hypothesis}

**ä¸´ç•Œå€¼**: {critical_values}

**è§£é‡Šæ ‡å‡†**: {interpretation}

**å‚è€ƒ**: {source}

---
""",
        },
        "reporting_standards": {
            "standard": """
### {title}

**å¿…å¡«å…ƒç´ **:
{elements}

**ç¤ºä¾‹æ ¼å¼**:
```
{example}
```

**å‚è€ƒ**: {source}

---
""",
        },
        "common_errors": {
            "error": """
### {title}

**é”™è¯¯æè¿°**: {description}

**ä¸ºä»€ä¹ˆé”™è¯¯**: {why_wrong}

**æ­£ç¡®åšæ³•**: {correct_approach}

**ä»£ç ç¤ºä¾‹**:
```python
{code_example}
```

**å‚è€ƒ**: {source}

---
""",
        },
    }

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__("UpdaterAgent", config)
        self.updates_dir = CALIBRATION_DIR / "updates"
        self.updates_dir.mkdir(parents=True, exist_ok=True)

    def _find_skill_path(self, skill_name: str) -> Optional[Path]:
        """æŸ¥æ‰¾æŠ€èƒ½ç›®å½•"""
        search_paths = [
            SKILLS_DIR / "classic-methods" / skill_name,
            SKILLS_DIR / "causal-ml" / skill_name,
            SKILLS_DIR / "ml-foundation" / skill_name,
            SKILLS_DIR / "infrastructure" / skill_name,
        ]

        for path in search_paths:
            if path.exists():
                return path

        return None

    def _create_backup(self, skill_path: Path) -> Path:
        """åˆ›å»ºæŠ€èƒ½ç›®å½•å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.updates_dir / f"{skill_path.name}_backup_{timestamp}"

        shutil.copytree(skill_path, backup_path, dirs_exist_ok=True)
        self.logger.info(f"å¤‡ä»½åˆ›å»º: {backup_path}")

        return backup_path

    def _gap_to_patch(
        self,
        gap: GapInfo,
        component: str,
        skill_path: Path
    ) -> Optional[UpdatePatch]:
        """å°†å·®è·è½¬æ¢ä¸ºæ›´æ–°è¡¥ä¸"""
        target_file = self.COMPONENT_FILE_MAP.get(component, "SKILL.md")
        full_path = skill_path / target_file

        # ç¡®å®šæ“ä½œç±»å‹
        if gap.existing_content:
            operation = "modify"
        else:
            operation = "add"

        # ç”Ÿæˆæ–°å†…å®¹
        new_content = self._generate_content(gap, component)

        if not new_content:
            return None

        # ç¡®å®šä¼˜å…ˆçº§
        priority_map = {"critical": 1, "major": 2, "minor": 3, "enhancement": 4}
        priority = priority_map.get(gap.severity, 3)

        return UpdatePatch(
            patch_id=gap.gap_id,
            target_file=target_file,
            operation=operation,
            location=gap.category,
            original_content=gap.existing_content,
            new_content=new_content,
            reason=gap.description,
            source_gaps=[gap.gap_id],
            priority=priority
        )

    def _generate_content(self, gap: GapInfo, component: str) -> str:
        """æ ¹æ®å·®è·ç”Ÿæˆæ–°å†…å®¹"""
        templates = self.CONTENT_TEMPLATES.get(component, {})

        # æ ¹æ®å·®è·ç±»å‹é€‰æ‹©æ¨¡æ¿
        if gap.category in ["assumption", "identification"]:
            template = templates.get("assumption", "")
            if template:
                return template.format(
                    title=gap.description[:50],
                    definition=gap.suggested_addition or "å¾…è¡¥å……",
                    intuition="å¾…è¡¥å……",
                    testability="å¾…è¯„ä¼°",
                    source=gap.source_paper
                )

        elif gap.category in ["method", "estimation"]:
            template = templates.get("method", "")
            if template:
                return template.format(
                    title=gap.description[:50],
                    formula=gap.suggested_addition or "å¾…è¡¥å……",
                    steps="1. å¾…è¡¥å……\n2. å¾…è¡¥å……",
                    standard_errors="å¾…è¡¥å……",
                    conditions="å¾…è¡¥å……",
                    source=gap.source_paper
                )

        elif gap.category in ["diagnostic", "test"]:
            template = templates.get("test", "")
            if template:
                return template.format(
                    title=gap.description[:50],
                    statistic=gap.suggested_addition or "å¾…è¡¥å……",
                    null_hypothesis="å¾…è¡¥å……",
                    critical_values="å¾…è¡¥å……",
                    interpretation="å¾…è¡¥å……",
                    source=gap.source_paper
                )

        elif gap.category in ["error", "common_errors"]:
            template = templates.get("error", "")
            if template:
                return template.format(
                    title=gap.description[:50],
                    description=gap.suggested_addition or "å¾…è¡¥å……",
                    why_wrong="å¾…è¡¥å……",
                    correct_approach="å¾…è¡¥å……",
                    code_example="# å¾…è¡¥å……",
                    source=gap.source_paper
                )

        # é»˜è®¤: ç®€å•æ–‡æœ¬
        return f"""
### {gap.description[:80]}

{gap.suggested_addition or 'å¾…è¡¥å……è¯¦ç»†å†…å®¹'}

**æ¥æº**: {gap.source_paper}

---
"""

    def _find_insertion_point(
        self,
        content: str,
        component: str,
        gap: GapInfo
    ) -> int:
        """æ‰¾åˆ°å†…å®¹æ’å…¥ä½ç½®"""
        lines = content.split('\n')

        # æŸ¥æ‰¾ç›¸å…³ç« èŠ‚
        section_headers = {
            "identification_assumptions": ["## è¯†åˆ«å‡è®¾", "## Assumptions", "## å‡è®¾"],
            "estimation_methods": ["## ä¼°è®¡æ–¹æ³•", "## Methods", "## æ–¹æ³•"],
            "diagnostic_tests": ["## è¯Šæ–­æµ‹è¯•", "## Diagnostics", "## è¯Šæ–­"],
            "reporting_standards": ["## æŠ¥å‘Šæ ‡å‡†", "## Reporting", "## æŠ¥å‘Š"],
            "common_errors": ["## å¸¸è§é”™è¯¯", "## Errors", "## é”™è¯¯"],
        }

        headers = section_headers.get(component, [])

        # æ‰¾åˆ°ç« èŠ‚æœ«å°¾
        for i, line in enumerate(lines):
            for header in headers:
                if header.lower() in line.lower():
                    # æ‰¾åˆ°ä¸‹ä¸€ä¸ª ## æ ‡é¢˜æˆ–æ–‡ä»¶æœ«å°¾
                    for j in range(i + 1, len(lines)):
                        if lines[j].startswith('## '):
                            return j
                    return len(lines)

        # æ²¡æ‰¾åˆ°åˆ™æ·»åŠ åˆ°æœ«å°¾
        return len(lines)

    def _apply_patch(
        self,
        patch: UpdatePatch,
        skill_path: Path
    ) -> bool:
        """åº”ç”¨å•ä¸ªè¡¥ä¸"""
        file_path = skill_path / patch.target_file

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        file_path.parent.mkdir(parents=True, exist_ok=True)

        try:
            if file_path.exists():
                content = file_path.read_text(encoding='utf-8')
            else:
                content = f"# {patch.target_file}\n\n"

            if patch.operation == "add":
                # æ‰¾åˆ°æ’å…¥ç‚¹
                lines = content.split('\n')
                insert_point = self._find_insertion_point(
                    content,
                    patch.target_file.replace("references/", "").replace(".md", ""),
                    None
                )
                lines.insert(insert_point, patch.new_content)
                new_content = '\n'.join(lines)

            elif patch.operation == "modify":
                # æ›¿æ¢åŸå†…å®¹
                if patch.original_content in content:
                    new_content = content.replace(
                        patch.original_content,
                        patch.new_content
                    )
                else:
                    # æ‰¾ä¸åˆ°åŸå†…å®¹åˆ™è¿½åŠ 
                    new_content = content + "\n" + patch.new_content

            elif patch.operation == "delete":
                new_content = content.replace(patch.original_content, "")

            else:
                return False

            file_path.write_text(new_content, encoding='utf-8')
            patch.applied = True

            self.logger.info(f"å·²åº”ç”¨è¡¥ä¸åˆ° {patch.target_file}")
            return True

        except Exception as e:
            self.logger.error(f"åº”ç”¨è¡¥ä¸å¤±è´¥: {e}")
            return False

    def _merge_patches(self, patches: List[UpdatePatch]) -> List[UpdatePatch]:
        """åˆå¹¶åŒä¸€æ–‡ä»¶çš„è¡¥ä¸"""
        by_file: Dict[str, List[UpdatePatch]] = {}

        for patch in patches:
            if patch.target_file not in by_file:
                by_file[patch.target_file] = []
            by_file[patch.target_file].append(patch)

        merged = []
        for target_file, file_patches in by_file.items():
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            file_patches.sort(key=lambda p: p.priority)

            # åˆå¹¶åŒä¸€æ–‡ä»¶çš„æ·»åŠ æ“ä½œ
            add_patches = [p for p in file_patches if p.operation == "add"]
            if len(add_patches) > 1:
                combined_content = "\n".join(p.new_content for p in add_patches)
                combined_gaps = []
                for p in add_patches:
                    combined_gaps.extend(p.source_gaps)

                merged.append(UpdatePatch(
                    patch_id=f"merged_{target_file.replace('/', '_')}",
                    target_file=target_file,
                    operation="add",
                    location="multiple",
                    original_content="",
                    new_content=combined_content,
                    reason=f"åˆå¹¶äº† {len(add_patches)} ä¸ªæ·»åŠ æ“ä½œ",
                    source_gaps=combined_gaps,
                    priority=min(p.priority for p in add_patches)
                ))
            else:
                merged.extend(add_patches)

            # ä¿ç•™å…¶ä»–æ“ä½œ
            merged.extend(p for p in file_patches if p.operation != "add")

        return merged

    def _generate_diff(self, patch: UpdatePatch, skill_path: Path) -> str:
        """ç”Ÿæˆ diff æ ¼å¼çš„å˜æ›´"""
        file_path = skill_path / patch.target_file

        if file_path.exists():
            original = file_path.read_text(encoding='utf-8').splitlines()
        else:
            original = []

        # æ¨¡æ‹Ÿåº”ç”¨è¡¥ä¸åçš„å†…å®¹
        if patch.operation == "add":
            modified = original + [""] + patch.new_content.splitlines()
        elif patch.operation == "modify":
            content = '\n'.join(original)
            new_content = content.replace(patch.original_content, patch.new_content)
            modified = new_content.splitlines()
        else:
            modified = original

        diff = difflib.unified_diff(
            original,
            modified,
            fromfile=f"a/{patch.target_file}",
            tofile=f"b/{patch.target_file}",
            lineterm=""
        )

        return '\n'.join(diff)

    def _generate_report(
        self,
        skill_name: str,
        patches: List[UpdatePatch],
        applied_count: int,
        files_updated: List[str],
        backup_path: Optional[Path]
    ) -> str:
        """ç”Ÿæˆæ›´æ–°æŠ¥å‘Š"""
        report = f"""# {skill_name} æ›´æ–°æŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¦‚è§ˆ

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| ç”Ÿæˆè¡¥ä¸æ•° | {len(patches)} |
| å·²åº”ç”¨è¡¥ä¸ | {applied_count} |
| æ›´æ–°æ–‡ä»¶æ•° | {len(files_updated)} |
| å¤‡ä»½ä½ç½® | {backup_path or 'æ— '} |

## è¡¥ä¸è¯¦æƒ…

"""
        for i, patch in enumerate(patches, 1):
            status = "âœ… å·²åº”ç”¨" if patch.applied else "â³ å¾…åº”ç”¨"
            priority_symbol = "ğŸ”´" if patch.priority == 1 else "ğŸŸ¡" if patch.priority == 2 else "ğŸŸ¢"

            report += f"""### {i}. {patch.target_file}

- **çŠ¶æ€**: {status}
- **ä¼˜å…ˆçº§**: {priority_symbol} P{patch.priority}
- **æ“ä½œ**: {patch.operation}
- **åŸå› **: {patch.reason}

**å˜æ›´å†…å®¹é¢„è§ˆ**:
```
{patch.new_content[:500]}{'...' if len(patch.new_content) > 500 else ''}
```

---

"""

        if files_updated:
            report += "## å·²æ›´æ–°æ–‡ä»¶\n\n"
            for f in files_updated:
                report += f"- `{f}`\n"

        return report

    async def process(self, input_data: UpdateInput) -> UpdateOutput:
        """
        æ‰§è¡Œæ–‡æ¡£æ›´æ–°

        Parameters
        ----------
        input_data : UpdateInput
            æ›´æ–°è¾“å…¥

        Returns
        -------
        UpdateOutput
            æ›´æ–°ç»“æœ
        """
        skill_name = input_data.skill_name

        self.logger.info(f"å¼€å§‹å¤„ç† {skill_name} çš„æ›´æ–°")

        # æŸ¥æ‰¾æŠ€èƒ½è·¯å¾„
        skill_path = self._find_skill_path(skill_name)
        if not skill_path:
            raise ValueError(f"æŠ€èƒ½ç›®å½•æœªæ‰¾åˆ°: {skill_name}")

        # åˆ›å»ºå¤‡ä»½
        backup_path = None
        if input_data.backup:
            backup_path = self._create_backup(skill_path)

        # ç”Ÿæˆè¡¥ä¸
        patches = []
        for component, output in input_data.gap_results.items():
            for gap in output.gaps:
                patch = self._gap_to_patch(gap, component, skill_path)
                if patch:
                    patches.append(patch)

        self.logger.info(f"ç”Ÿæˆäº† {len(patches)} ä¸ªè¡¥ä¸")

        # åˆå¹¶è¡¥ä¸
        patches = self._merge_patches(patches)
        self.logger.info(f"åˆå¹¶å {len(patches)} ä¸ªè¡¥ä¸")

        # åº”ç”¨è¡¥ä¸
        applied_count = 0
        files_updated = []

        if input_data.auto_apply:
            for patch in patches:
                if self._apply_patch(patch, skill_path):
                    applied_count += 1
                    if patch.target_file not in files_updated:
                        files_updated.append(patch.target_file)

            self.logger.info(f"åº”ç”¨äº† {applied_count} ä¸ªè¡¥ä¸")
        else:
            self.logger.info("è¡¥ä¸æœªè‡ªåŠ¨åº”ç”¨ (auto_apply=False)")

        # ä¿å­˜è¡¥ä¸æ–‡ä»¶
        patches_dir = self.updates_dir / skill_name
        patches_dir.mkdir(parents=True, exist_ok=True)

        for patch in patches:
            patch_file = patches_dir / f"{patch.patch_id}.patch"
            patch_file.write_text(
                self._generate_diff(patch, skill_path),
                encoding='utf-8'
            )

        # ä¿å­˜è¡¥ä¸å…ƒæ•°æ®
        meta_file = patches_dir / "patches.json"
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump([
                {
                    "patch_id": p.patch_id,
                    "target_file": p.target_file,
                    "operation": p.operation,
                    "priority": p.priority,
                    "reason": p.reason,
                    "applied": p.applied,
                }
                for p in patches
            ], f, ensure_ascii=False, indent=2)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(
            skill_name, patches, applied_count, files_updated, backup_path
        )

        return UpdateOutput(
            skill_name=skill_name,
            patches_generated=len(patches),
            patches_applied=applied_count,
            files_updated=files_updated,
            patches=patches,
            backup_path=backup_path,
            report=report
        )

    async def apply_pending_patches(
        self,
        skill_name: str,
        patch_ids: Optional[List[str]] = None
    ) -> int:
        """åº”ç”¨å¾…å¤„ç†çš„è¡¥ä¸"""
        patches_dir = self.updates_dir / skill_name
        meta_file = patches_dir / "patches.json"

        if not meta_file.exists():
            self.logger.warning(f"æ— å¾…å¤„ç†è¡¥ä¸: {skill_name}")
            return 0

        skill_path = self._find_skill_path(skill_name)
        if not skill_path:
            raise ValueError(f"æŠ€èƒ½ç›®å½•æœªæ‰¾åˆ°: {skill_name}")

        with open(meta_file, 'r', encoding='utf-8') as f:
            patches_meta = json.load(f)

        applied = 0
        for meta in patches_meta:
            if meta["applied"]:
                continue

            if patch_ids and meta["patch_id"] not in patch_ids:
                continue

            patch_file = patches_dir / f"{meta['patch_id']}.patch"
            if patch_file.exists():
                # ç®€åŒ–: æ ‡è®°ä¸ºå·²åº”ç”¨
                meta["applied"] = True
                applied += 1

        # æ›´æ–°å…ƒæ•°æ®
        with open(meta_file, 'w', encoding='utf-8') as f:
            json.dump(patches_meta, f, ensure_ascii=False, indent=2)

        self.logger.info(f"åº”ç”¨äº† {applied} ä¸ªå¾…å¤„ç†è¡¥ä¸")
        return applied

    def save_results(
        self,
        output: UpdateOutput,
        output_dir: Optional[Path] = None
    ) -> Path:
        """ä¿å­˜æ›´æ–°ç»“æœ"""
        output_dir = output_dir or self.updates_dir / output.skill_name
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æŠ¥å‘Š
        report_path = output_dir / "update_report.md"
        report_path.write_text(output.report, encoding='utf-8')

        self.logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        return output_dir


if __name__ == "__main__":
    from .gap_analyzer import GapAnalysisOutput, GapInfo

    async def test():
        updater = UpdaterAgent()

        # æ¨¡æ‹Ÿè¾“å…¥
        test_input = UpdateInput(
            skill_name="estimator-did",
            gap_results={
                "identification_assumptions": GapAnalysisOutput(
                    skill_name="estimator-did",
                    component="identification_assumptions",
                    gaps=[
                        GapInfo(
                            gap_id="test1",
                            category="assumption",
                            severity="major",
                            description="ç¼ºå°‘ No Anticipation å‡è®¾",
                            source_paper="Callaway & Sant'Anna (2021)",
                            source_section="assumptions",
                            suggested_addition="åœ¨å¤„ç†å‘ç”Ÿå‰ï¼Œå¤„ç†ç»„çš„è¡Œä¸ºä¸åº”å‘ç”Ÿå˜åŒ–ã€‚"
                        )
                    ],
                    coverage_score=0.8,
                    papers_analyzed=5,
                    summary=""
                ),
            },
            auto_apply=False,
            backup=False
        )

        result = await updater.run(test_input)
        print(f"ç”Ÿæˆè¡¥ä¸æ•°: {result.patches_generated}")
        print(f"å·²åº”ç”¨è¡¥ä¸: {result.patches_applied}")
        print(f"\n{result.report}")

    asyncio.run(test())
